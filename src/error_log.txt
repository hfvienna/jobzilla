2023-07-28 19:41:26,400 - ERROR - Error occurred in processing file 8284cebf-3042-49d7-aaf8-70cde5e52c3e_Senior Researcher for Generative AI (m_f_x) _ Dynatrace Careers.json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 10446 tokens. Please reduce the length of the messages.
2023-07-28 20:41:58,586 - ERROR - Error occurred in processing file 8284cebf-3042-49d7-aaf8-70cde5e52c3e_Senior Researcher for Generative AI (m_f_x) _ Dynatrace Careers.json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 9240 tokens. Please reduce the length of the messages.
2023-07-28 20:51:52,078 - ERROR - Error occurred in processing file 75189123-1ead-4b19-b1b4-27eb6b6e6daf_Jooble - AI Scientist_NLP Researcher (m_w_d).json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 8724 tokens. Please reduce the length of the messages.
2023-07-28 21:11:10,225 - ERROR - Error occurred in processing file 99bfa780-ca26-4350-a79f-e7577ea5a2b2_Job Application for Gestionnaire des opérations et de l'approvisionnement at GiveDirectly.json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 9354 tokens. Please reduce the length of the messages.
2023-07-31 11:13:52,823 - ERROR - Error occurred in processing file 8284cebf-3042-49d7-aaf8-70cde5e52c3e_Senior Researcher for Generative AI (m_f_x) _ Dynatrace Careers.json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 9240 tokens. Please reduce the length of the messages.
2023-07-31 11:15:44,337 - ERROR - Error occurred in processing file 75189123-1ead-4b19-b1b4-27eb6b6e6daf_Jooble - AI Scientist_NLP Researcher (m_w_d).json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 8724 tokens. Please reduce the length of the messages.
2023-07-31 12:25:50,716 - ERROR - Error occurred in processing file 8284cebf-3042-49d7-aaf8-70cde5e52c3e_Senior Researcher for Generative AI (m_f_x) _ Dynatrace Careers.json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 9240 tokens. Please reduce the length of the messages.
2023-07-31 12:25:51,007 - ERROR - Error occurred in processing file 75189123-1ead-4b19-b1b4-27eb6b6e6daf_Jooble - AI Scientist_NLP Researcher (m_w_d).json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 8724 tokens. Please reduce the length of the messages.
2023-07-31 12:27:20,417 - ERROR - Error occurred in processing file 99bfa780-ca26-4350-a79f-e7577ea5a2b2_Job Application for Gestionnaire des opérations et de l'approvisionnement at GiveDirectly.json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 9354 tokens. Please reduce the length of the messages.
2023-07-31 12:50:28,347 - ERROR - Error occurred in processing file 43f37ac7-a459-4d43-914d-43de7f6d0ced_Registration of Interest — AI Governance and Strategy - Remote _ Rethink Priorities Careers.json with error Expecting value: line 1 column 1 (char 0)
2023-07-31 13:02:19,585 - ERROR - Error occurred in processing file 8284cebf-3042-49d7-aaf8-70cde5e52c3e_Senior Researcher for Generative AI (m_f_x) _ Dynatrace Careers.json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 9240 tokens. Please reduce the length of the messages.
2023-07-31 13:02:20,300 - ERROR - Error occurred in processing file 75189123-1ead-4b19-b1b4-27eb6b6e6daf_Jooble - AI Scientist_NLP Researcher (m_w_d).json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 8724 tokens. Please reduce the length of the messages.
2023-07-31 13:02:20,661 - ERROR - Error occurred in processing file 99bfa780-ca26-4350-a79f-e7577ea5a2b2_Job Application for Gestionnaire des opérations et de l'approvisionnement at GiveDirectly.json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 9354 tokens. Please reduce the length of the messages.
2023-07-31 14:16:46,085 - ERROR - Error occurred in processing file 8284cebf-3042-49d7-aaf8-70cde5e52c3e_Senior Researcher for Generative AI (m_f_x) _ Dynatrace Careers.json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 9240 tokens. Please reduce the length of the messages.
2023-07-31 14:16:46,493 - ERROR - Error occurred in processing file 75189123-1ead-4b19-b1b4-27eb6b6e6daf_Jooble - AI Scientist_NLP Researcher (m_w_d).json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 8724 tokens. Please reduce the length of the messages.
2023-07-31 14:16:47,345 - ERROR - Error occurred in processing file 99bfa780-ca26-4350-a79f-e7577ea5a2b2_Job Application for Gestionnaire des opérations et de l'approvisionnement at GiveDirectly.json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 9354 tokens. Please reduce the length of the messages.
2023-07-31 14:17:44,149 - ERROR - Error occurred in processing file 43f37ac7-a459-4d43-914d-43de7f6d0ced_Registration of Interest — AI Governance and Strategy - Remote _ Rethink Priorities Careers.json with error Expecting value: line 1 column 1 (char 0)
2023-07-31 14:19:14,975 - ERROR - Error occurred in processing file 8284cebf-3042-49d7-aaf8-70cde5e52c3e_Senior Researcher for Generative AI (m_f_x) _ Dynatrace Careers.json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 9240 tokens. Please reduce the length of the messages.
2023-07-31 14:19:15,794 - ERROR - Error occurred in processing file 75189123-1ead-4b19-b1b4-27eb6b6e6daf_Jooble - AI Scientist_NLP Researcher (m_w_d).json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 8724 tokens. Please reduce the length of the messages.
2023-07-31 14:19:16,203 - ERROR - Error occurred in processing file 99bfa780-ca26-4350-a79f-e7577ea5a2b2_Job Application for Gestionnaire des opérations et de l'approvisionnement at GiveDirectly.json with error This model's maximum context length is 8192 tokens. However, your messages resulted in 9354 tokens. Please reduce the length of the messages.
2023-07-31 14:20:12,734 - ERROR - Error occurred in processing file 43f37ac7-a459-4d43-914d-43de7f6d0ced_Registration of Interest — AI Governance and Strategy - Remote _ Rethink Priorities Careers.json with error Expecting value: line 1 column 1 (char 0)
